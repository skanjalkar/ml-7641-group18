Compiling data for:  
Number of files: 4953
Test first 5 files from X: ['1100-1200/X_chunk_605812_9.npy', '1100-1200/X_chunk_561252_12.npy', '1100-1200/X_chunk_563918_28.npy', '1100-1200/X_chunk_263179_5.npy', '1100-1200/X_chunk_472813_19.npy']
Test first 5 files from Y: ['1100-1200/y_chunk_605812_9.npy', '1100-1200/y_chunk_561252_12.npy', '1100-1200/y_chunk_563918_28.npy', '1100-1200/y_chunk_263179_5.npy', '1100-1200/y_chunk_472813_19.npy']
633984 507187 126797
Using cuda device
Epoch 1-----------------
Step [0], Loss: 24.6951
Step [10], Loss: 5.1559
Step [20], Loss: 4.0040
Step [30], Loss: 4.5750
Step [40], Loss: 3.9324
Step [50], Loss: 4.3086
Step [60], Loss: 3.9910
Step [70], Loss: 2.9022
Step [80], Loss: 3.7403
Step [90], Loss: 3.5703
Step [100], Loss: 3.7483
Step [110], Loss: 3.9900
Step [120], Loss: 2.9002
Step [130], Loss: 3.6139
Step [140], Loss: 3.0974
Step [150], Loss: 3.3149
Step [160], Loss: 3.4837
Step [170], Loss: 2.8838
Step [180], Loss: 2.9782
Step [190], Loss: 2.7729
Step [200], Loss: 2.7931
Step [210], Loss: 3.0610
Step [220], Loss: 2.8297
Step [230], Loss: 2.2138
Step [240], Loss: 3.1022
Step [250], Loss: 3.4609
Step [260], Loss: 3.5090
Step [270], Loss: 1.9709
Step [280], Loss: 1.9146
Step [290], Loss: 2.2933
Step [300], Loss: 2.2204
Step [310], Loss: 2.3239
Step [320], Loss: 2.7739
Step [330], Loss: 2.2594
Step [340], Loss: 2.6725
Step [350], Loss: 2.5086
Step [360], Loss: 3.2195
Step [370], Loss: 3.2391
Step [380], Loss: 3.0696
Step [390], Loss: 2.2273
Step [400], Loss: 2.3519
Step [410], Loss: 2.9292
Step [420], Loss: 2.5923
Step [430], Loss: 1.9088
Step [440], Loss: 2.2990
Step [450], Loss: 2.3158
Step [460], Loss: 2.2562
Step [470], Loss: 2.8181
Step [480], Loss: 2.8340
Step [490], Loss: 2.1579
correct predicitons: 79858.0
Total items 126797
Test Error: 
 Accuracy: 63.0%, Avg loss: 2.258232 

Epoch 2-----------------
Step [0], Loss: 2.6785
Step [10], Loss: 2.1375
Step [20], Loss: 2.7595
Step [30], Loss: 2.0509
Step [40], Loss: 2.8113
Step [50], Loss: 3.2156
Step [60], Loss: 2.1869
Step [70], Loss: 2.4795
Step [80], Loss: 2.8392
Step [90], Loss: 2.0768
Step [100], Loss: 2.5739
Step [110], Loss: 2.0461
Step [120], Loss: 2.5700
Step [130], Loss: 1.9158
Step [140], Loss: 2.7171
Step [150], Loss: 3.4550
Step [160], Loss: 3.2028
Step [170], Loss: 3.0653
Step [180], Loss: 2.8286
Step [190], Loss: 3.9684
Step [200], Loss: 2.6073
Step [210], Loss: 2.5677
Step [220], Loss: 3.1899
Step [230], Loss: 2.5789
Step [240], Loss: 2.2950
Step [250], Loss: 2.0594
Step [260], Loss: 2.0149
Step [270], Loss: 2.1430
Step [280], Loss: 1.7524
Step [290], Loss: 2.3556
Step [300], Loss: 2.2422
Step [310], Loss: 2.4302
Step [320], Loss: 2.5649
Step [330], Loss: 2.4875
Step [340], Loss: 2.6467
Step [350], Loss: 2.3673
Step [360], Loss: 2.4518
Step [370], Loss: 2.1659
Step [380], Loss: 2.5798
Step [390], Loss: 2.5958
Step [400], Loss: 2.1027
Step [410], Loss: 2.8715
Step [420], Loss: 3.5774
Step [430], Loss: 2.8167
Step [440], Loss: 2.0591
Step [450], Loss: 1.8231
Step [460], Loss: 2.5997
Step [470], Loss: 2.5998
Step [480], Loss: 2.4710
Step [490], Loss: 2.6060
correct predicitons: 81739.0
Total items 126797
Test Error: 
 Accuracy: 64.5%, Avg loss: 1.237695 

Epoch 3-----------------
Step [0], Loss: 1.8919
Step [10], Loss: 2.3220
Step [20], Loss: 1.8935
Step [30], Loss: 1.9734
Step [40], Loss: 2.3788
Step [50], Loss: 2.5308
Step [60], Loss: 2.1107
Step [70], Loss: 3.4617
Step [80], Loss: 2.7570
Step [90], Loss: 3.3916
Step [100], Loss: 2.6513
Step [110], Loss: 2.7550
Step [120], Loss: 2.5336
Step [130], Loss: 2.4353
Step [140], Loss: 2.5239
Step [150], Loss: 1.9670
Step [160], Loss: 2.9428
Step [170], Loss: 1.8558
Step [180], Loss: 2.1870
Step [190], Loss: 2.1157
Step [200], Loss: 2.3344
Step [210], Loss: 2.3788
Step [220], Loss: 2.3908
Step [230], Loss: 2.3659
Step [240], Loss: 2.5754
Step [250], Loss: 2.1928
Step [260], Loss: 3.0811
Step [270], Loss: 2.7837
Step [280], Loss: 1.5111
Step [290], Loss: 2.1948
Step [300], Loss: 2.1045
Step [310], Loss: 1.4331
Step [320], Loss: 2.4206
Step [330], Loss: 1.7802
Step [340], Loss: 2.9480
Step [350], Loss: 2.5761
Step [360], Loss: 1.9074
Step [370], Loss: 2.3984
Step [380], Loss: 2.7780
Step [390], Loss: 2.0157
Step [400], Loss: 2.3265
Step [410], Loss: 2.3970
Step [420], Loss: 2.1003
Step [430], Loss: 2.2360
Step [440], Loss: 2.6859
Step [450], Loss: 2.1274
Step [460], Loss: 2.9126
Step [470], Loss: 2.4111
Step [480], Loss: 2.2861
Step [490], Loss: 1.6741
correct predicitons: 82314.0
Total items 126797
Test Error: 
 Accuracy: 64.9%, Avg loss: 2.239419 

Epoch 4-----------------
Step [0], Loss: 2.7905
Step [10], Loss: 2.0790
Step [20], Loss: 2.4996
Step [30], Loss: 3.0724
Step [40], Loss: 3.4356
Step [50], Loss: 1.8046
Step [60], Loss: 2.1408
Step [70], Loss: 2.2310
Step [80], Loss: 2.7882
Step [90], Loss: 3.2972
Step [100], Loss: 2.1419
Step [110], Loss: 1.9144
Step [120], Loss: 2.1380
Step [130], Loss: 2.7815
Step [140], Loss: 2.6185
Step [150], Loss: 2.4744
Step [160], Loss: 2.5574
Step [170], Loss: 1.7716
Step [180], Loss: 2.4984
Step [190], Loss: 3.7365
Step [200], Loss: 2.1446
Step [210], Loss: 2.2235
Step [220], Loss: 1.6409
Step [230], Loss: 2.3734
Step [240], Loss: 1.9970
Step [250], Loss: 2.1252
Step [260], Loss: 1.9396
Step [270], Loss: 2.1669
Step [280], Loss: 2.4320
Step [290], Loss: 2.6378
Step [300], Loss: 1.6821
Step [310], Loss: 2.7174
Step [320], Loss: 2.2643
Step [330], Loss: 1.7693
Step [340], Loss: 2.2494
Step [350], Loss: 2.7131
Step [360], Loss: 2.6637
Step [370], Loss: 2.4804
Step [380], Loss: 1.7777
Step [390], Loss: 2.6599
Step [400], Loss: 2.2671
Step [410], Loss: 2.3682
Step [420], Loss: 2.7436
Step [430], Loss: 2.1622
Step [440], Loss: 2.0818
Step [450], Loss: 2.5038
Step [460], Loss: 1.8916
Step [470], Loss: 2.4764
Step [480], Loss: 2.1543
Step [490], Loss: 1.8230
correct predicitons: 82789.0
Total items 126797
Test Error: 
 Accuracy: 65.3%, Avg loss: 1.695158 

Epoch 5-----------------
Step [0], Loss: 2.2241
Step [10], Loss: 2.0720
Step [20], Loss: 2.5438
Step [30], Loss: 2.5268
Step [40], Loss: 2.8589
Step [50], Loss: 2.7854
Step [60], Loss: 2.4861
Step [70], Loss: 2.5000
Step [80], Loss: 2.1616
Step [90], Loss: 3.1575
Step [100], Loss: 2.7187
Step [110], Loss: 2.7625
Step [120], Loss: 3.0349
Step [130], Loss: 2.0806
Step [140], Loss: 3.0039
Step [150], Loss: 3.0391
Step [160], Loss: 2.5985
Step [170], Loss: 1.8209
Step [180], Loss: 2.1564
Step [190], Loss: 2.9413
Step [200], Loss: 2.7801
Step [210], Loss: 1.8568
Step [220], Loss: 3.1660
Step [230], Loss: 2.7315
Step [240], Loss: 2.3309
Step [250], Loss: 3.2683
Step [260], Loss: 2.1143
Step [270], Loss: 2.1017
Step [280], Loss: 2.8618
Step [290], Loss: 2.1467
Step [300], Loss: 2.6452
Step [310], Loss: 2.9579
Step [320], Loss: 1.8776
Step [330], Loss: 2.2643
Step [340], Loss: 2.4070
Step [350], Loss: 3.1777
Step [360], Loss: 2.8512
Step [370], Loss: 2.2398
Step [380], Loss: 2.4717
Step [390], Loss: 2.4354
Step [400], Loss: 2.0195
Step [410], Loss: 1.9768
Step [420], Loss: 1.8557
Step [430], Loss: 2.1297
Step [440], Loss: 2.3931
Step [450], Loss: 1.8741
Step [460], Loss: 2.7713
Step [470], Loss: 2.2668
Step [480], Loss: 2.6927
Step [490], Loss: 2.1987
correct predicitons: 83814.0
Total items 126797
Test Error: 
 Accuracy: 66.1%, Avg loss: 2.229694 

Epoch 6-----------------
Step [0], Loss: 2.7424
Step [10], Loss: 2.3741
Step [20], Loss: 1.9124
Step [30], Loss: 1.7753
Step [40], Loss: 1.8489
Step [50], Loss: 2.5789
Step [60], Loss: 1.8829
Step [70], Loss: 1.5707
Step [80], Loss: 2.1901
Step [90], Loss: 2.8754
Step [100], Loss: 2.5006
Step [110], Loss: 2.9451
Step [120], Loss: 2.6646
Step [130], Loss: 2.8844
Step [140], Loss: 2.2486
Step [150], Loss: 2.8571
Step [160], Loss: 2.3576
Step [170], Loss: 2.4639
Step [180], Loss: 2.8425
Step [190], Loss: 1.5800
Step [200], Loss: 2.7108
Step [210], Loss: 2.3472
Step [220], Loss: 2.4182
Step [230], Loss: 2.4974
Step [240], Loss: 2.0576
Step [250], Loss: 1.7890
Step [260], Loss: 2.1844
Step [270], Loss: 2.9171
Step [280], Loss: 1.8078
Step [290], Loss: 2.3694
Step [300], Loss: 1.7062
Step [310], Loss: 2.1820
Step [320], Loss: 2.1629
Step [330], Loss: 2.4702
Step [340], Loss: 1.8955
Step [350], Loss: 2.0664
Step [360], Loss: 1.8125
Step [370], Loss: 2.8076
Step [380], Loss: 2.3284
Step [390], Loss: 2.0497
Step [400], Loss: 1.9541
Step [410], Loss: 2.7670
Step [420], Loss: 2.0760
Step [430], Loss: 1.4479
Step [440], Loss: 2.3647
Step [450], Loss: 2.4604
Step [460], Loss: 2.5429
Step [470], Loss: 2.4327
Step [480], Loss: 1.9224
Step [490], Loss: 1.8514
correct predicitons: 84168.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 2.229404 

Epoch 7-----------------
Step [0], Loss: 2.4980
Step [10], Loss: 2.7379
Step [20], Loss: 3.2736
Step [30], Loss: 3.0972
Step [40], Loss: 2.0266
Step [50], Loss: 1.9867
Step [60], Loss: 2.1869
Step [70], Loss: 2.1032
Step [80], Loss: 2.4154
Step [90], Loss: 2.1662
Step [100], Loss: 4.7822
Step [110], Loss: 4.1036
Step [120], Loss: 3.4525
Step [130], Loss: 4.1057
Step [140], Loss: 3.4494
Step [150], Loss: 4.5493
Step [160], Loss: 4.4062
Step [170], Loss: 3.4849
Step [180], Loss: 3.7394
Step [190], Loss: 2.7969
Step [200], Loss: 1.8069
Step [210], Loss: 2.0604
Step [220], Loss: 2.3333
Step [230], Loss: 2.2272
Step [240], Loss: 2.1655
Step [250], Loss: 2.2275
Step [260], Loss: 2.1713
Step [270], Loss: 2.4306
Step [280], Loss: 2.2561
Step [290], Loss: 2.7780
Step [300], Loss: 2.5201
Step [310], Loss: 1.3940
Step [320], Loss: 1.6884
Step [330], Loss: 2.3354
Step [340], Loss: 2.1690
Step [350], Loss: 2.3268
Step [360], Loss: 2.6581
Step [370], Loss: 1.8808
Step [380], Loss: 2.1613
Step [390], Loss: 2.3737
Step [400], Loss: 2.4894
Step [410], Loss: 2.6841
Step [420], Loss: 2.4090
Step [430], Loss: 2.5008
Step [440], Loss: 3.6569
Step [450], Loss: 2.7535
Step [460], Loss: 2.1585
Step [470], Loss: 2.3995
Step [480], Loss: 2.8399
Step [490], Loss: 2.0325
correct predicitons: 84046.0
Total items 126797
Test Error: 
 Accuracy: 66.3%, Avg loss: 2.227307 

Epoch 8-----------------
Step [0], Loss: 2.3586
Step [10], Loss: 2.2337
Step [20], Loss: 1.4719
Step [30], Loss: 2.9093
Step [40], Loss: 2.3915
Step [50], Loss: 1.9160
Step [60], Loss: 2.0624
Step [70], Loss: 2.2619
Step [80], Loss: 1.6591
Step [90], Loss: 2.1333
Step [100], Loss: 1.5309
Step [110], Loss: 1.7267
Step [120], Loss: 1.8737
Step [130], Loss: 2.0363
Step [140], Loss: 1.9235
Step [150], Loss: 2.5605
Step [160], Loss: 1.9360
Step [170], Loss: 2.1779
Step [180], Loss: 2.2219
Step [190], Loss: 2.5487
Step [200], Loss: 2.0347
Step [210], Loss: 2.5021
Step [220], Loss: 2.3316
Step [230], Loss: 1.9981
Step [240], Loss: 2.5896
Step [250], Loss: 3.2494
Step [260], Loss: 2.0307
Step [270], Loss: 2.2235
Step [280], Loss: 2.4368
Step [290], Loss: 1.7934
Step [300], Loss: 2.0882
Step [310], Loss: 1.9232
Step [320], Loss: 2.4885
Step [330], Loss: 2.4745
Step [340], Loss: 2.9839
Step [350], Loss: 1.9599
Step [360], Loss: 2.8034
Step [370], Loss: 2.8976
Step [380], Loss: 3.1545
Step [390], Loss: 2.7974
Step [400], Loss: 2.3837
Step [410], Loss: 3.3247
Step [420], Loss: 3.0052
Step [430], Loss: 2.5013
Step [440], Loss: 1.5927
Step [450], Loss: 2.4267
Step [460], Loss: 2.3818
Step [470], Loss: 2.1991
Step [480], Loss: 2.1760
Step [490], Loss: 3.8227
correct predicitons: 81940.0
Total items 126797
Test Error: 
 Accuracy: 64.6%, Avg loss: 4.048522 

Epoch 9-----------------
Step [0], Loss: 3.1811
Step [10], Loss: 2.6724
Step [20], Loss: 2.1966
Step [30], Loss: 2.5755
Step [40], Loss: 2.2217
Step [50], Loss: 2.3395
Step [60], Loss: 2.1415
Step [70], Loss: 2.8770
Step [80], Loss: 2.9180
Step [90], Loss: 2.3192
Step [100], Loss: 2.5902
Step [110], Loss: 2.5072
Step [120], Loss: 2.6475
Step [130], Loss: 2.9050
Step [140], Loss: 2.4021
Step [150], Loss: 2.4259
Step [160], Loss: 2.0434
Step [170], Loss: 2.3230
Step [180], Loss: 1.8874
Step [190], Loss: 2.7035
Step [200], Loss: 2.4425
Step [210], Loss: 1.6670
Step [220], Loss: 1.9692
Step [230], Loss: 2.9068
Step [240], Loss: 2.3889
Step [250], Loss: 2.0185
Step [260], Loss: 2.8345
Step [270], Loss: 2.1912
Step [280], Loss: 3.0685
Step [290], Loss: 2.1058
Step [300], Loss: 1.9710
Step [310], Loss: 2.8589
Step [320], Loss: 2.2448
Step [330], Loss: 2.7857
Step [340], Loss: 2.3209
Step [350], Loss: 2.0957
Step [360], Loss: 1.9809
Step [370], Loss: 2.1016
Step [380], Loss: 2.3163
Step [390], Loss: 2.2124
Step [400], Loss: 2.1048
Step [410], Loss: 2.4748
Step [420], Loss: 2.4230
Step [430], Loss: 2.5453
Step [440], Loss: 3.6097
Step [450], Loss: 2.2730
Step [460], Loss: 2.1245
Step [470], Loss: 2.5459
Step [480], Loss: 2.3185
Step [490], Loss: 2.5422
correct predicitons: 84095.0
Total items 126797
Test Error: 
 Accuracy: 66.3%, Avg loss: 1.432988 

Epoch 10-----------------
Step [0], Loss: 2.5544
Step [10], Loss: 2.2028
Step [20], Loss: 1.8648
Step [30], Loss: 2.3499
Step [40], Loss: 2.6638
Step [50], Loss: 1.9284
Step [60], Loss: 2.2122
Step [70], Loss: 2.2220
Step [80], Loss: 1.9121
Step [90], Loss: 2.6951
Step [100], Loss: 2.3350
Step [110], Loss: 2.5561
Step [120], Loss: 2.1691
Step [130], Loss: 2.4711
Step [140], Loss: 2.7919
Step [150], Loss: 1.9870
Step [160], Loss: 1.5599
Step [170], Loss: 2.6217
Step [180], Loss: 3.0191
Step [190], Loss: 1.9900
Step [200], Loss: 1.9566
Step [210], Loss: 2.3185
Step [220], Loss: 1.9560
Step [230], Loss: 2.7461
Step [240], Loss: 1.9696
Step [250], Loss: 2.2916
Step [260], Loss: 2.1005
Step [270], Loss: 1.7511
Step [280], Loss: 2.8969
Step [290], Loss: 2.2565
Step [300], Loss: 1.8507
Step [310], Loss: 2.0620
Step [320], Loss: 2.4492
Step [330], Loss: 2.6672
Step [340], Loss: 1.7077
Step [350], Loss: 1.8206
Step [360], Loss: 1.9813
Step [370], Loss: 2.2351
Step [380], Loss: 2.4652
Step [390], Loss: 1.7496
Step [400], Loss: 2.7315
Step [410], Loss: 2.4248
Step [420], Loss: 2.4558
Step [430], Loss: 2.9063
Step [440], Loss: 2.2817
Step [450], Loss: 2.5167
Step [460], Loss: 2.4006
Step [470], Loss: 2.0720
Step [480], Loss: 2.5073
Step [490], Loss: 2.6106
correct predicitons: 84180.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 1.894330 

Epoch 11-----------------
Step [0], Loss: 1.9347
Step [10], Loss: 1.5661
Step [20], Loss: 2.5605
Step [30], Loss: 2.5394
Step [40], Loss: 2.2297
Step [50], Loss: 1.7873
Step [60], Loss: 2.5937
Step [70], Loss: 2.2384
Step [80], Loss: 2.0724
Step [90], Loss: 1.9777
Step [100], Loss: 2.7860
Step [110], Loss: 2.4785
Step [120], Loss: 2.0416
Step [130], Loss: 1.7297
Step [140], Loss: 1.7563
Step [150], Loss: 1.7872
Step [160], Loss: 2.6974
Step [170], Loss: 2.2833
Step [180], Loss: 2.4481
Step [190], Loss: 2.6727
Step [200], Loss: 2.1601
Step [210], Loss: 2.3408
Step [220], Loss: 2.8720
Step [230], Loss: 2.4837
Step [240], Loss: 2.2442
Step [250], Loss: 1.7735
Step [260], Loss: 1.6219
Step [270], Loss: 3.4417
Step [280], Loss: 2.1558
Step [290], Loss: 2.5100
Step [300], Loss: 2.8095
Step [310], Loss: 2.7280
Step [320], Loss: 2.6295
Step [330], Loss: 2.4096
Step [340], Loss: 2.5115
Step [350], Loss: 2.5651
Step [360], Loss: 2.6970
Step [370], Loss: 4.2755
Step [380], Loss: 3.6307
Step [390], Loss: 2.9156
Step [400], Loss: 2.7040
Step [410], Loss: 2.7977
Step [420], Loss: 2.5046
Step [430], Loss: 1.9268
Step [440], Loss: 2.2592
Step [450], Loss: 2.2652
Step [460], Loss: 2.1539
Step [470], Loss: 2.5057
Step [480], Loss: 1.9947
Step [490], Loss: 3.1887
correct predicitons: 84048.0
Total items 126797
Test Error: 
 Accuracy: 66.3%, Avg loss: 1.696033 

Epoch 12-----------------
Step [0], Loss: 2.0356
Step [10], Loss: 2.2467
Step [20], Loss: 2.1279
Step [30], Loss: 2.1116
Step [40], Loss: 1.9799
Step [50], Loss: 2.1010
Step [60], Loss: 2.6240
Step [70], Loss: 1.8917
Step [80], Loss: 1.9628
Step [90], Loss: 2.0670
Step [100], Loss: 2.0050
Step [110], Loss: 2.2631
Step [120], Loss: 2.6425
Step [130], Loss: 2.1398
Step [140], Loss: 1.8823
Step [150], Loss: 2.0513
Step [160], Loss: 2.7535
Step [170], Loss: 2.0029
Step [180], Loss: 2.5951
Step [190], Loss: 1.8053
Step [200], Loss: 1.8490
Step [210], Loss: 2.4232
Step [220], Loss: 1.7938
Step [230], Loss: 1.7130
Step [240], Loss: 1.9886
Step [250], Loss: 2.1961
Step [260], Loss: 1.7851
Step [270], Loss: 1.9526
Step [280], Loss: 2.1400
Step [290], Loss: 1.9350
Step [300], Loss: 2.7100
Step [310], Loss: 2.3526
Step [320], Loss: 2.4589
Step [330], Loss: 1.8212
Step [340], Loss: 2.0045
Step [350], Loss: 2.1034
Step [360], Loss: 2.2714
Step [370], Loss: 1.7230
Step [380], Loss: 2.7597
Step [390], Loss: 2.5265
Step [400], Loss: 2.5759
Step [410], Loss: 1.9498
Step [420], Loss: 2.7991
Step [430], Loss: 2.4353
Step [440], Loss: 2.4052
Step [450], Loss: 1.9911
Step [460], Loss: 2.6166
Step [470], Loss: 2.9532
Step [480], Loss: 2.5230
Step [490], Loss: 2.1825
correct predicitons: 84190.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 1.468376 

Epoch 13-----------------
Step [0], Loss: 2.3549
Step [10], Loss: 2.8974
Step [20], Loss: 2.2850
Step [30], Loss: 2.8906
Step [40], Loss: 2.0485
Step [50], Loss: 1.9919
Step [60], Loss: 2.2879
Step [70], Loss: 2.2831
Step [80], Loss: 1.5364
Step [90], Loss: 1.7606
Step [100], Loss: 2.1268
Step [110], Loss: 2.5046
Step [120], Loss: 2.5978
Step [130], Loss: 2.4548
Step [140], Loss: 2.7096
Step [150], Loss: 2.8974
Step [160], Loss: 2.7102
Step [170], Loss: 2.4914
Step [180], Loss: 2.1629
Step [190], Loss: 1.6200
Step [200], Loss: 2.6729
Step [210], Loss: 1.9339
Step [220], Loss: 1.9315
Step [230], Loss: 1.3098
Step [240], Loss: 2.0011
Step [250], Loss: 1.9266
Step [260], Loss: 2.8133
Step [270], Loss: 2.3440
Step [280], Loss: 2.3751
Step [290], Loss: 2.6287
Step [300], Loss: 2.4999
Step [310], Loss: 2.2235
Step [320], Loss: 2.2279
Step [330], Loss: 2.6378
Step [340], Loss: 2.9266
Step [350], Loss: 3.0306
Step [360], Loss: 1.9327
Step [370], Loss: 2.3848
Step [380], Loss: 2.4711
Step [390], Loss: 2.7946
Step [400], Loss: 2.2868
Step [410], Loss: 2.7631
Step [420], Loss: 1.7992
Step [430], Loss: 2.4547
Step [440], Loss: 3.3454
Step [450], Loss: 1.9271
Step [460], Loss: 2.5619
Step [470], Loss: 2.2290
Step [480], Loss: 2.0221
Step [490], Loss: 2.9060
correct predicitons: 84223.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 1.568558 

Epoch 14-----------------
Step [0], Loss: 2.1415
Step [10], Loss: 2.2743
Step [20], Loss: 2.2596
Step [30], Loss: 2.2851
Step [40], Loss: 1.7997
Step [50], Loss: 1.7873
Step [60], Loss: 1.8942
Step [70], Loss: 2.2946
Step [80], Loss: 1.9437
Step [90], Loss: 2.2727
Step [100], Loss: 1.9025
Step [110], Loss: 1.8148
Step [120], Loss: 2.5873
Step [130], Loss: 2.7072
Step [140], Loss: 2.7214
Step [150], Loss: 2.0106
Step [160], Loss: 2.4344
Step [170], Loss: 2.7668
Step [180], Loss: 2.2712
Step [190], Loss: 2.5706
Step [200], Loss: 1.7824
Step [210], Loss: 2.7286
Step [220], Loss: 2.7564
Step [230], Loss: 2.3904
Step [240], Loss: 2.6153
Step [250], Loss: 2.2089
Step [260], Loss: 2.0594
Step [270], Loss: 2.4246
Step [280], Loss: 2.5924
Step [290], Loss: 2.5574
Step [300], Loss: 3.0085
Step [310], Loss: 2.1083
Step [320], Loss: 2.6355
Step [330], Loss: 2.6281
Step [340], Loss: 1.9817
Step [350], Loss: 2.1427
Step [360], Loss: 1.8198
Step [370], Loss: 2.5928
Step [380], Loss: 2.1298
Step [390], Loss: 2.3764
Step [400], Loss: 2.1302
Step [410], Loss: 2.4912
Step [420], Loss: 1.9724
Step [430], Loss: 2.2153
Step [440], Loss: 2.6845
Step [450], Loss: 2.5946
Step [460], Loss: 1.8543
Step [470], Loss: 2.7555
Step [480], Loss: 2.2575
Step [490], Loss: 1.9518
correct predicitons: 84360.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.429891 

Epoch 15-----------------
Step [0], Loss: 2.0658
Step [10], Loss: 3.2772
Step [20], Loss: 1.9065
Step [30], Loss: 2.7739
Step [40], Loss: 1.8094
Step [50], Loss: 3.1020
Step [60], Loss: 2.7624
Step [70], Loss: 2.2400
Step [80], Loss: 2.8150
Step [90], Loss: 2.5191
Step [100], Loss: 2.2865
Step [110], Loss: 2.2579
Step [120], Loss: 2.1134
Step [130], Loss: 2.9256
Step [140], Loss: 2.4678
Step [150], Loss: 2.8706
Step [160], Loss: 2.0204
Step [170], Loss: 2.1263
Step [180], Loss: 1.9839
Step [190], Loss: 2.2316
Step [200], Loss: 2.1806
Step [210], Loss: 2.5416
Step [220], Loss: 2.3979
Step [230], Loss: 2.2649
Step [240], Loss: 2.2057
Step [250], Loss: 2.5136
Step [260], Loss: 1.9764
Step [270], Loss: 2.4625
Step [280], Loss: 2.3613
Step [290], Loss: 2.7010
Step [300], Loss: 1.8494
Step [310], Loss: 2.3160
Step [320], Loss: 2.2042
Step [330], Loss: 3.0458
Step [340], Loss: 2.1505
Step [350], Loss: 2.4103
Step [360], Loss: 2.4456
Step [370], Loss: 2.2203
Step [380], Loss: 2.2209
Step [390], Loss: 1.8870
Step [400], Loss: 2.9472
Step [410], Loss: 2.4449
Step [420], Loss: 1.8895
Step [430], Loss: 2.4044
Step [440], Loss: 1.8883
Step [450], Loss: 2.1154
Step [460], Loss: 2.0901
Step [470], Loss: 2.4129
Step [480], Loss: 2.2295
Step [490], Loss: 1.6632
correct predicitons: 84225.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 1.674467 

Epoch 16-----------------
Step [0], Loss: 2.0617
Step [10], Loss: 2.0496
Step [20], Loss: 2.2307
Step [30], Loss: 2.5221
Step [40], Loss: 2.3274
Step [50], Loss: 2.5485
Step [60], Loss: 2.0731
Step [70], Loss: 2.2009
Step [80], Loss: 2.6878
Step [90], Loss: 2.7203
Step [100], Loss: 2.3517
Step [110], Loss: 2.8827
Step [120], Loss: 1.8568
Step [130], Loss: 2.8445
Step [140], Loss: 2.3069
Step [150], Loss: 2.2713
Step [160], Loss: 2.5916
Step [170], Loss: 2.0996
Step [180], Loss: 2.0540
Step [190], Loss: 2.1170
Step [200], Loss: 1.9325
Step [210], Loss: 2.0341
Step [220], Loss: 2.4457
Step [230], Loss: 2.4694
Step [240], Loss: 2.6168
Step [250], Loss: 1.9452
Step [260], Loss: 2.2380
Step [270], Loss: 2.1773
Step [280], Loss: 2.4958
Step [290], Loss: 2.4888
Step [300], Loss: 1.5469
Step [310], Loss: 2.2399
Step [320], Loss: 2.2560
Step [330], Loss: 2.4438
Step [340], Loss: 2.1152
Step [350], Loss: 2.4676
Step [360], Loss: 2.5820
Step [370], Loss: 2.8075
Step [380], Loss: 2.0685
Step [390], Loss: 2.8775
Step [400], Loss: 1.8309
Step [410], Loss: 1.8006
Step [420], Loss: 1.9858
Step [430], Loss: 2.7402
Step [440], Loss: 2.4498
Step [450], Loss: 1.5721
Step [460], Loss: 2.7940
Step [470], Loss: 2.1991
Step [480], Loss: 2.7231
Step [490], Loss: 2.3372
correct predicitons: 84284.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.657089 

Epoch 17-----------------
Step [0], Loss: 2.0828
Step [10], Loss: 1.9512
Step [20], Loss: 2.3730
Step [30], Loss: 2.4586
Step [40], Loss: 2.2288
Step [50], Loss: 2.4510
Step [60], Loss: 3.5192
Step [70], Loss: 2.3863
Step [80], Loss: 2.3285
Step [90], Loss: 2.4284
Step [100], Loss: 2.4183
Step [110], Loss: 2.0675
Step [120], Loss: 2.0192
Step [130], Loss: 2.0396
Step [140], Loss: 1.8399
Step [150], Loss: 2.2174
Step [160], Loss: 1.6552
Step [170], Loss: 1.5545
Step [180], Loss: 1.8622
Step [190], Loss: 2.3483
Step [200], Loss: 1.5410
Step [210], Loss: 2.1205
Step [220], Loss: 2.5572
Step [230], Loss: 2.3024
Step [240], Loss: 2.1217
Step [250], Loss: 2.3121
Step [260], Loss: 2.4057
Step [270], Loss: 2.1667
Step [280], Loss: 2.1052
Step [290], Loss: 2.0741
Step [300], Loss: 2.9749
Step [310], Loss: 1.8951
Step [320], Loss: 2.8648
Step [330], Loss: 2.2194
Step [340], Loss: 3.0464
Step [350], Loss: 2.7816
Step [360], Loss: 3.0194
Step [370], Loss: 1.8300
Step [380], Loss: 2.6645
Step [390], Loss: 2.0062
Step [400], Loss: 2.4918
Step [410], Loss: 2.2498
Step [420], Loss: 2.6281
Step [430], Loss: 2.5952
Step [440], Loss: 2.3319
Step [450], Loss: 2.5921
Step [460], Loss: 1.7085
Step [470], Loss: 2.0734
Step [480], Loss: 2.0463
Step [490], Loss: 2.2182
correct predicitons: 84324.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.635963 

Epoch 18-----------------
Step [0], Loss: 2.3170
Step [10], Loss: 2.3467
Step [20], Loss: 2.8140
Step [30], Loss: 2.3069
Step [40], Loss: 2.1147
Step [50], Loss: 2.2478
Step [60], Loss: 2.5152
Step [70], Loss: 2.0766
Step [80], Loss: 1.9514
Step [90], Loss: 1.7638
Step [100], Loss: 2.4647
Step [110], Loss: 2.8229
Step [120], Loss: 2.6360
Step [130], Loss: 2.3113
Step [140], Loss: 2.8010
Step [150], Loss: 2.9331
Step [160], Loss: 1.8320
Step [170], Loss: 2.2355
Step [180], Loss: 2.4953
Step [190], Loss: 1.7508
Step [200], Loss: 2.3262
Step [210], Loss: 1.6437
Step [220], Loss: 1.8458
Step [230], Loss: 2.3589
Step [240], Loss: 2.3382
Step [250], Loss: 2.0376
Step [260], Loss: 3.1936
Step [270], Loss: 2.7014
Step [280], Loss: 2.3532
Step [290], Loss: 2.5010
Step [300], Loss: 2.3919
Step [310], Loss: 1.8918
Step [320], Loss: 1.6153
Step [330], Loss: 2.5847
Step [340], Loss: 1.7983
Step [350], Loss: 2.1291
Step [360], Loss: 2.2609
Step [370], Loss: 2.3469
Step [380], Loss: 2.1876
Step [390], Loss: 2.0653
Step [400], Loss: 2.9159
Step [410], Loss: 2.0628
Step [420], Loss: 2.1349
Step [430], Loss: 2.4110
Step [440], Loss: 2.5588
Step [450], Loss: 2.0652
Step [460], Loss: 2.2675
Step [470], Loss: 2.1624
Step [480], Loss: 1.8166
Step [490], Loss: 3.2595
correct predicitons: 84319.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.670724 

Epoch 19-----------------
Step [0], Loss: 1.8405
Step [10], Loss: 3.0285
Step [20], Loss: 2.6293
Step [30], Loss: 1.8654
Step [40], Loss: 2.5197
Step [50], Loss: 1.7875
Step [60], Loss: 2.2209
Step [70], Loss: 2.5208
Step [80], Loss: 2.2268
Step [90], Loss: 2.8181
Step [100], Loss: 2.1117
Step [110], Loss: 2.1827
Step [120], Loss: 3.0334
Step [130], Loss: 2.7001
Step [140], Loss: 1.6970
Step [150], Loss: 2.3196
Step [160], Loss: 2.2515
Step [170], Loss: 2.5494
Step [180], Loss: 1.6871
Step [190], Loss: 2.3505
Step [200], Loss: 2.1310
Step [210], Loss: 1.4493
Step [220], Loss: 2.0136
Step [230], Loss: 2.7028
Step [240], Loss: 2.3800
Step [250], Loss: 2.9074
Step [260], Loss: 2.8510
Step [270], Loss: 2.0133
Step [280], Loss: 2.5455
Step [290], Loss: 2.4774
Step [300], Loss: 2.1162
Step [310], Loss: 1.9436
Step [320], Loss: 1.7875
Step [330], Loss: 2.8493
Step [340], Loss: 1.9907
Step [350], Loss: 1.7487
Step [360], Loss: 2.2505
Step [370], Loss: 2.2674
Step [380], Loss: 2.7411
Step [390], Loss: 1.7167
Step [400], Loss: 2.2980
Step [410], Loss: 2.4201
Step [420], Loss: 1.6956
Step [430], Loss: 2.0443
Step [440], Loss: 2.9471
Step [450], Loss: 2.6721
Step [460], Loss: 1.6665
Step [470], Loss: 1.4547
Step [480], Loss: 2.3912
Step [490], Loss: 2.1352
correct predicitons: 84253.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 1.647026 

Epoch 20-----------------
Step [0], Loss: 1.6449
Step [10], Loss: 2.5026
Step [20], Loss: 2.3058
Step [30], Loss: 1.6372
Step [40], Loss: 2.4837
Step [50], Loss: 2.4713
Step [60], Loss: 1.9773
Step [70], Loss: 2.3533
Step [80], Loss: 2.9800
Step [90], Loss: 2.1193
Step [100], Loss: 2.0827
Step [110], Loss: 1.8917
Step [120], Loss: 2.2478
Step [130], Loss: 2.4609
Step [140], Loss: 2.6030
Step [150], Loss: 2.6599
Step [160], Loss: 2.7084
Step [170], Loss: 2.2142
Step [180], Loss: 1.4676
Step [190], Loss: 2.3327
Step [200], Loss: 2.3683
Step [210], Loss: 2.2857
Step [220], Loss: 1.8360
Step [230], Loss: 1.6974
Step [240], Loss: 2.9398
Step [250], Loss: 2.7364
Step [260], Loss: 2.3784
Step [270], Loss: 2.1229
Step [280], Loss: 1.8978
Step [290], Loss: 2.0937
Step [300], Loss: 2.7332
Step [310], Loss: 2.8984
Step [320], Loss: 1.7555
Step [330], Loss: 2.2000
Step [340], Loss: 2.2928
Step [350], Loss: 2.1854
Step [360], Loss: 2.3916
Step [370], Loss: 2.2314
Step [380], Loss: 1.9677
Step [390], Loss: 2.6079
Step [400], Loss: 1.9013
Step [410], Loss: 2.2767
Step [420], Loss: 1.7293
Step [430], Loss: 2.1933
Step [440], Loss: 2.1800
Step [450], Loss: 2.6737
Step [460], Loss: 1.9035
Step [470], Loss: 2.0054
Step [480], Loss: 2.3828
Step [490], Loss: 2.1630
correct predicitons: 84346.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.713691 

Epoch 21-----------------
Step [0], Loss: 2.1320
Step [10], Loss: 2.5421
Step [20], Loss: 2.1500
Step [30], Loss: 2.6588
Step [40], Loss: 2.4333
Step [50], Loss: 1.8820
Step [60], Loss: 2.2858
Step [70], Loss: 2.3519
Step [80], Loss: 1.6169
Step [90], Loss: 2.3460
Step [100], Loss: 2.0647
Step [110], Loss: 2.3463
Step [120], Loss: 1.8493
Step [130], Loss: 2.1743
Step [140], Loss: 2.4790
Step [150], Loss: 2.2088
Step [160], Loss: 2.2584
Step [170], Loss: 2.6896
Step [180], Loss: 1.8090
Step [190], Loss: 1.9909
Step [200], Loss: 1.9075
Step [210], Loss: 2.2802
Step [220], Loss: 1.5495
Step [230], Loss: 1.7491
Step [240], Loss: 2.0421
Step [250], Loss: 2.7118
Step [260], Loss: 2.0597
Step [270], Loss: 2.0420
Step [280], Loss: 2.7973
Step [290], Loss: 2.5925
Step [300], Loss: 2.0988
Step [310], Loss: 2.1263
Step [320], Loss: 1.8011
Step [330], Loss: 2.1427
Step [340], Loss: 1.7291
Step [350], Loss: 2.5678
Step [360], Loss: 2.5454
Step [370], Loss: 2.4495
Step [380], Loss: 2.4251
Step [390], Loss: 2.0425
Step [400], Loss: 2.4491
Step [410], Loss: 2.5431
Step [420], Loss: 2.4420
Step [430], Loss: 1.7399
Step [440], Loss: 2.3105
Step [450], Loss: 2.4690
Step [460], Loss: 2.1436
Step [470], Loss: 2.2935
Step [480], Loss: 2.4981
Step [490], Loss: 2.2800
correct predicitons: 84278.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.675431 

Epoch 22-----------------
Step [0], Loss: 1.5818
Step [10], Loss: 2.2469
Step [20], Loss: 2.0186
Step [30], Loss: 2.7121
Step [40], Loss: 1.2655
Step [50], Loss: 2.3688
Step [60], Loss: 1.6799
Step [70], Loss: 2.5936
Step [80], Loss: 2.7187
Step [90], Loss: 1.7202
Step [100], Loss: 1.8341
Step [110], Loss: 2.7035
Step [120], Loss: 2.5757
Step [130], Loss: 2.3541
Step [140], Loss: 2.0861
Step [150], Loss: 2.1206
Step [160], Loss: 2.2708
Step [170], Loss: 2.0018
Step [180], Loss: 2.0672
Step [190], Loss: 2.3516
Step [200], Loss: 2.0927
Step [210], Loss: 2.8313
Step [220], Loss: 2.4403
Step [230], Loss: 2.4287
Step [240], Loss: 1.8770
Step [250], Loss: 2.3794
Step [260], Loss: 2.3929
Step [270], Loss: 2.7600
Step [280], Loss: 2.2779
Step [290], Loss: 2.3497
Step [300], Loss: 2.2201
Step [310], Loss: 2.3482
Step [320], Loss: 2.0583
Step [330], Loss: 2.7191
Step [340], Loss: 2.4127
Step [350], Loss: 2.5377
Step [360], Loss: 1.5442
Step [370], Loss: 2.0050
Step [380], Loss: 2.6210
Step [390], Loss: 2.3423
Step [400], Loss: 2.0839
Step [410], Loss: 2.1835
Step [420], Loss: 1.5977
Step [430], Loss: 1.8463
Step [440], Loss: 2.2509
Step [450], Loss: 2.8739
Step [460], Loss: 2.2114
Step [470], Loss: 2.6271
Step [480], Loss: 1.6433
Step [490], Loss: 2.9685
correct predicitons: 84275.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 1.681679 

Early stopping triggered
Training Complete
Confusion Matrix:
            Predicted 0    Predicted 1
True 0      70993          7693
True 1      37365          10746
