/home/hice1/lks3/anaconda3/envs/deeplearning/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Compiling data for:  
Number of files: 4953
Test first 5 files from X: ['1100-1200/X_chunk_605812_9.npy', '1100-1200/X_chunk_561252_12.npy', '1100-1200/X_chunk_563918_28.npy', '1100-1200/X_chunk_263179_5.npy', '1100-1200/X_chunk_472813_19.npy']
Test first 5 files from Y: ['1100-1200/y_chunk_605812_9.npy', '1100-1200/y_chunk_561252_12.npy', '1100-1200/y_chunk_563918_28.npy', '1100-1200/y_chunk_263179_5.npy', '1100-1200/y_chunk_472813_19.npy']
633984 507187 126797
Using cuda device
Epoch 1-----------------
Step [0], Loss: 0.7186
Step [10], Loss: 0.6833
Step [20], Loss: 0.6864
Step [30], Loss: 0.6678
Step [40], Loss: 0.6723
Step [50], Loss: 0.6668
Step [60], Loss: 0.6477
Step [70], Loss: 0.6564
Step [80], Loss: 0.6451
Step [90], Loss: 0.6329
Step [100], Loss: 0.6484
Step [110], Loss: 0.6597
Step [120], Loss: 0.6314
Step [130], Loss: 0.6589
Step [140], Loss: 0.6719
Step [150], Loss: 0.6699
Step [160], Loss: 0.6543
Step [170], Loss: 0.6497
Step [180], Loss: 0.6437
Step [190], Loss: 0.6377
Step [200], Loss: 0.6443
Step [210], Loss: 0.6268
Step [220], Loss: 0.6345
Step [230], Loss: 0.6473
Step [240], Loss: 0.6487
Step [250], Loss: 0.6444
Step [260], Loss: 0.6317
Step [270], Loss: 0.6231
Step [280], Loss: 0.6447
Step [290], Loss: 0.6362
Step [300], Loss: 0.6192
Step [310], Loss: 0.6391
Step [320], Loss: 0.6083
Step [330], Loss: 0.6110
Step [340], Loss: 0.6231
Step [350], Loss: 0.6320
Step [360], Loss: 0.6079
Step [370], Loss: 0.6422
Step [380], Loss: 0.6293
Step [390], Loss: 0.6290
Step [400], Loss: 0.6403
Step [410], Loss: 0.6310
Step [420], Loss: 0.6435
Step [430], Loss: 0.6308
Step [440], Loss: 0.6255
Step [450], Loss: 0.6459
Step [460], Loss: 0.6122
Step [470], Loss: 0.6268
Step [480], Loss: 0.6275
Step [490], Loss: 0.6382
correct predicitons: 83169.0
Total items 126797
Test Error: 
 Accuracy: 65.6%, Avg loss: 34.404627 

Epoch 2-----------------
Step [0], Loss: 0.6031
Step [10], Loss: 0.5980
Step [20], Loss: 0.6225
Step [30], Loss: 0.6075
Step [40], Loss: 0.6093
Step [50], Loss: 0.6115
Step [60], Loss: 0.6140
Step [70], Loss: 0.6187
Step [80], Loss: 0.6126
Step [90], Loss: 0.6089
Step [100], Loss: 0.6063
Step [110], Loss: 0.6030
Step [120], Loss: 0.5934
Step [130], Loss: 0.6180
Step [140], Loss: 0.6085
Step [150], Loss: 0.6274
Step [160], Loss: 0.6063
Step [170], Loss: 0.6262
Step [180], Loss: 0.6143
Step [190], Loss: 0.6117
Step [200], Loss: 0.6357
Step [210], Loss: 0.6062
Step [220], Loss: 0.6021
Step [230], Loss: 0.6433
Step [240], Loss: 0.6148
Step [250], Loss: 0.6119
Step [260], Loss: 0.6038
Step [270], Loss: 0.6245
Step [280], Loss: 0.5935
Step [290], Loss: 0.6307
Step [300], Loss: 0.6021
Step [310], Loss: 0.6210
Step [320], Loss: 0.6098
Step [330], Loss: 0.6272
Step [340], Loss: 0.5992
Step [350], Loss: 0.6191
Step [360], Loss: 0.6127
Step [370], Loss: 0.6155
Step [380], Loss: 0.6013
Step [390], Loss: 0.5999
Step [400], Loss: 0.5880
Step [410], Loss: 0.5966
Step [420], Loss: 0.6067
Step [430], Loss: 0.6162
Step [440], Loss: 0.6019
Step [450], Loss: 0.6205
Step [460], Loss: 0.5976
Step [470], Loss: 0.5935
Step [480], Loss: 0.6058
Step [490], Loss: 0.6021
correct predicitons: 84098.0
Total items 126797
Test Error: 
 Accuracy: 66.3%, Avg loss: 33.674828 

Epoch 3-----------------
Step [0], Loss: 0.5730
Step [10], Loss: 0.6010
Step [20], Loss: 0.5930
Step [30], Loss: 0.5966
Step [40], Loss: 0.6120
Step [50], Loss: 0.5936
Step [60], Loss: 0.6091
Step [70], Loss: 0.5950
Step [80], Loss: 0.6044
Step [90], Loss: 0.6026
Step [100], Loss: 0.6113
Step [110], Loss: 0.5886
Step [120], Loss: 0.5906
Step [130], Loss: 0.6045
Step [140], Loss: 0.6127
Step [150], Loss: 0.5893
Step [160], Loss: 0.5996
Step [170], Loss: 0.5917
Step [180], Loss: 0.5905
Step [190], Loss: 0.5887
Step [200], Loss: 0.6014
Step [210], Loss: 0.5882
Step [220], Loss: 0.5983
Step [230], Loss: 0.6054
Step [240], Loss: 0.6055
Step [250], Loss: 0.6028
Step [260], Loss: 0.5686
Step [270], Loss: 0.6039
Step [280], Loss: 0.6047
Step [290], Loss: 0.5920
Step [300], Loss: 0.6119
Step [310], Loss: 0.6034
Step [320], Loss: 0.6045
Step [330], Loss: 0.6245
Step [340], Loss: 0.6015
Step [350], Loss: 0.6185
Step [360], Loss: 0.5945
Step [370], Loss: 0.6104
Step [380], Loss: 0.5949
Step [390], Loss: 0.5836
Step [400], Loss: 0.6222
Step [410], Loss: 0.6159
Step [420], Loss: 0.6113
Step [430], Loss: 0.6193
Step [440], Loss: 0.5894
Step [450], Loss: 0.6149
Step [460], Loss: 0.5970
Step [470], Loss: 0.5810
Step [480], Loss: 0.5899
Step [490], Loss: 0.5835
correct predicitons: 84583.0
Total items 126797
Test Error: 
 Accuracy: 66.7%, Avg loss: 33.292365 

Epoch 4-----------------
Step [0], Loss: 0.5927
Step [10], Loss: 0.5797
Step [20], Loss: 0.5829
Step [30], Loss: 0.5589
Step [40], Loss: 0.5813
Step [50], Loss: 0.5720
Step [60], Loss: 0.5785
Step [70], Loss: 0.5868
Step [80], Loss: 0.5948
Step [90], Loss: 0.5854
Step [100], Loss: 0.5959
Step [110], Loss: 0.5930
Step [120], Loss: 0.6239
Step [130], Loss: 0.5523
Step [140], Loss: 0.5855
Step [150], Loss: 0.5792
Step [160], Loss: 0.5905
Step [170], Loss: 0.5824
Step [180], Loss: 0.5997
Step [190], Loss: 0.5901
Step [200], Loss: 0.5761
Step [210], Loss: 0.6179
Step [220], Loss: 0.5843
Step [230], Loss: 0.5694
Step [240], Loss: 0.5839
Step [250], Loss: 0.5989
Step [260], Loss: 0.5944
Step [270], Loss: 0.6132
Step [280], Loss: 0.5971
Step [290], Loss: 0.5726
Step [300], Loss: 0.5768
Step [310], Loss: 0.5906
Step [320], Loss: 0.5731
Step [330], Loss: 0.5996
Step [340], Loss: 0.5677
Step [350], Loss: 0.5773
Step [360], Loss: 0.5851
Step [370], Loss: 0.5972
Step [380], Loss: 0.5965
Step [390], Loss: 0.5920
Step [400], Loss: 0.5815
Step [410], Loss: 0.5888
Step [420], Loss: 0.6158
Step [430], Loss: 0.6006
Step [440], Loss: 0.5898
Step [450], Loss: 0.5809
Step [460], Loss: 0.5869
Step [470], Loss: 0.6084
Step [480], Loss: 0.6005
Step [490], Loss: 0.6154
correct predicitons: 84565.0
Total items 126797
Test Error: 
 Accuracy: 66.7%, Avg loss: 33.306041 

Epoch 5-----------------
Step [0], Loss: 0.5889
Step [10], Loss: 0.5863
Step [20], Loss: 0.5814
Step [30], Loss: 0.5666
Step [40], Loss: 0.5590
Step [50], Loss: 0.5750
Step [60], Loss: 0.5490
Step [70], Loss: 0.5806
Step [80], Loss: 0.5801
Step [90], Loss: 0.5663
Step [100], Loss: 0.5736
Step [110], Loss: 0.5874
Step [120], Loss: 0.5608
Step [130], Loss: 0.5564
Step [140], Loss: 0.5625
Step [150], Loss: 0.5782
Step [160], Loss: 0.5843
Step [170], Loss: 0.5876
Step [180], Loss: 0.5707
Step [190], Loss: 0.5518
Step [200], Loss: 0.5865
Step [210], Loss: 0.5949
Step [220], Loss: 0.5821
Step [230], Loss: 0.5840
Step [240], Loss: 0.5604
Step [250], Loss: 0.5704
Step [260], Loss: 0.5810
Step [270], Loss: 0.5688
Step [280], Loss: 0.5745
Step [290], Loss: 0.5895
Step [300], Loss: 0.5550
Step [310], Loss: 0.5723
Step [320], Loss: 0.5731
Step [330], Loss: 0.5538
Step [340], Loss: 0.5870
Step [350], Loss: 0.5866
Step [360], Loss: 0.5823
Step [370], Loss: 0.5623
Step [380], Loss: 0.5768
Step [390], Loss: 0.5874
Step [400], Loss: 0.5674
Step [410], Loss: 0.5699
Step [420], Loss: 0.5909
Step [430], Loss: 0.5564
Step [440], Loss: 0.5517
Step [450], Loss: 0.5939
Step [460], Loss: 0.5767
Step [470], Loss: 0.5835
Step [480], Loss: 0.5730
Step [490], Loss: 0.5702
correct predicitons: 84442.0
Total items 126797
Test Error: 
 Accuracy: 66.6%, Avg loss: 33.401241 

Epoch 6-----------------
Step [0], Loss: 0.5456
Step [10], Loss: 0.5743
Step [20], Loss: 0.5580
Step [30], Loss: 0.5603
Step [40], Loss: 0.5537
Step [50], Loss: 0.5486
Step [60], Loss: 0.5623
Step [70], Loss: 0.5668
Step [80], Loss: 0.5734
Step [90], Loss: 0.5524
Step [100], Loss: 0.5819
Step [110], Loss: 0.5592
Step [120], Loss: 0.5740
Step [130], Loss: 0.5523
Step [140], Loss: 0.5948
Step [150], Loss: 0.5536
Step [160], Loss: 0.5737
Step [170], Loss: 0.5532
Step [180], Loss: 0.5535
Step [190], Loss: 0.5490
Step [200], Loss: 0.5661
Step [210], Loss: 0.5704
Step [220], Loss: 0.5606
Step [230], Loss: 0.5586
Step [240], Loss: 0.5456
Step [250], Loss: 0.5453
Step [260], Loss: 0.5653
Step [270], Loss: 0.5654
Step [280], Loss: 0.5620
Step [290], Loss: 0.5714
Step [300], Loss: 0.5513
Step [310], Loss: 0.5577
Step [320], Loss: 0.5673
Step [330], Loss: 0.5599
Step [340], Loss: 0.5778
Step [350], Loss: 0.5501
Step [360], Loss: 0.5616
Step [370], Loss: 0.5526
Step [380], Loss: 0.5469
Step [390], Loss: 0.5557
Step [400], Loss: 0.5344
Step [410], Loss: 0.5670
Step [420], Loss: 0.5592
Step [430], Loss: 0.5482
Step [440], Loss: 0.5840
Step [450], Loss: 0.5627
Step [460], Loss: 0.5655
Step [470], Loss: 0.5541
Step [480], Loss: 0.5772
Step [490], Loss: 0.5621
correct predicitons: 84740.0
Total items 126797
Test Error: 
 Accuracy: 66.8%, Avg loss: 33.166217 

Epoch 7-----------------
Step [0], Loss: 0.5504
Step [10], Loss: 0.5194
Step [20], Loss: 0.5337
Step [30], Loss: 0.5306
Step [40], Loss: 0.5171
Step [50], Loss: 0.5395
Step [60], Loss: 0.5454
Step [70], Loss: 0.5454
Step [80], Loss: 0.5399
Step [90], Loss: 0.5263
Step [100], Loss: 0.5259
Step [110], Loss: 0.5288
Step [120], Loss: 0.5626
Step [130], Loss: 0.5470
Step [140], Loss: 0.5496
Step [150], Loss: 0.5347
Step [160], Loss: 0.5210
Step [170], Loss: 0.5263
Step [180], Loss: 0.5849
Step [190], Loss: 0.5353
Step [200], Loss: 0.5437
Step [210], Loss: 0.5523
Step [220], Loss: 0.5417
Step [230], Loss: 0.5648
Step [240], Loss: 0.5440
Step [250], Loss: 0.5812
Step [260], Loss: 0.5439
Step [270], Loss: 0.5593
Step [280], Loss: 0.5346
Step [290], Loss: 0.5497
Step [300], Loss: 0.5520
Step [310], Loss: 0.5765
Step [320], Loss: 0.5405
Step [330], Loss: 0.5425
Step [340], Loss: 0.5666
Step [350], Loss: 0.5417
Step [360], Loss: 0.5419
Step [370], Loss: 0.5723
Step [380], Loss: 0.5404
Step [390], Loss: 0.5367
Step [400], Loss: 0.5816
Step [410], Loss: 0.5686
Step [420], Loss: 0.5635
Step [430], Loss: 0.5320
Step [440], Loss: 0.5563
Step [450], Loss: 0.5213
Step [460], Loss: 0.5378
Step [470], Loss: 0.5663
Step [480], Loss: 0.5626
Step [490], Loss: 0.5549
correct predicitons: 84530.0
Total items 126797
Test Error: 
 Accuracy: 66.7%, Avg loss: 33.333271 

Epoch 8-----------------
Step [0], Loss: 0.5102
Step [10], Loss: 0.5278
Step [20], Loss: 0.5101
Step [30], Loss: 0.4965
Step [40], Loss: 0.5226
Step [50], Loss: 0.5098
Step [60], Loss: 0.5247
Step [70], Loss: 0.5228
Step [80], Loss: 0.5391
Step [90], Loss: 0.5261
Step [100], Loss: 0.5358
Step [110], Loss: 0.5333
Step [120], Loss: 0.5018
Step [130], Loss: 0.5195
Step [140], Loss: 0.5239
Step [150], Loss: 0.5439
Step [160], Loss: 0.5200
Step [170], Loss: 0.5098
Step [180], Loss: 0.5250
Step [190], Loss: 0.5317
Step [200], Loss: 0.5351
Step [210], Loss: 0.5245
Step [220], Loss: 0.5313
Step [230], Loss: 0.5203
Step [240], Loss: 0.5181
Step [250], Loss: 0.5346
Step [260], Loss: 0.5182
Step [270], Loss: 0.5173
Step [280], Loss: 0.5022
Step [290], Loss: 0.5371
Step [300], Loss: 0.5436
Step [310], Loss: 0.5204
Step [320], Loss: 0.5239
Step [330], Loss: 0.5348
Step [340], Loss: 0.5169
Step [350], Loss: 0.5252
Step [360], Loss: 0.5278
Step [370], Loss: 0.5230
Step [380], Loss: 0.5192
Step [390], Loss: 0.5113
Step [400], Loss: 0.5321
Step [410], Loss: 0.5248
Step [420], Loss: 0.5046
Step [430], Loss: 0.5027
Step [440], Loss: 0.5136
Step [450], Loss: 0.5290
Step [460], Loss: 0.5411
Step [470], Loss: 0.5153
Step [480], Loss: 0.5110
Step [490], Loss: 0.5206
correct predicitons: 84353.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 33.471166 

Epoch 9-----------------
Step [0], Loss: 0.4889
Step [10], Loss: 0.4838
Step [20], Loss: 0.4879
Step [30], Loss: 0.4952
Step [40], Loss: 0.5019
Step [50], Loss: 0.5047
Step [60], Loss: 0.4800
Step [70], Loss: 0.4956
Step [80], Loss: 0.5162
Step [90], Loss: 0.5052
Step [100], Loss: 0.5100
Step [110], Loss: 0.4890
Step [120], Loss: 0.4967
Step [130], Loss: 0.4768
Step [140], Loss: 0.4944
Step [150], Loss: 0.5456
Step [160], Loss: 0.5400
Step [170], Loss: 0.5386
Step [180], Loss: 0.4918
Step [190], Loss: 0.4943
Step [200], Loss: 0.4789
Step [210], Loss: 0.4746
Step [220], Loss: 0.4944
Step [230], Loss: 0.4932
Step [240], Loss: 0.4914
Step [250], Loss: 0.5017
Step [260], Loss: 0.4849
Step [270], Loss: 0.4951
Step [280], Loss: 0.5236
Step [290], Loss: 0.4923
Step [300], Loss: 0.4994
Step [310], Loss: 0.5046
Step [320], Loss: 0.4915
Step [330], Loss: 0.5051
Step [340], Loss: 0.5041
Step [350], Loss: 0.5073
Step [360], Loss: 0.4996
Step [370], Loss: 0.5259
Step [380], Loss: 0.5132
Step [390], Loss: 0.5168
Step [400], Loss: 0.5166
Step [410], Loss: 0.5031
Step [420], Loss: 0.5052
Step [430], Loss: 0.5017
Step [440], Loss: 0.5085
Step [450], Loss: 0.5190
Step [460], Loss: 0.4876
Step [470], Loss: 0.5167
Step [480], Loss: 0.4915
Step [490], Loss: 0.4907
correct predicitons: 83831.0
Total items 126797
Test Error: 
 Accuracy: 66.1%, Avg loss: 33.886105 

Epoch 10-----------------
Step [0], Loss: 0.4515
Step [10], Loss: 0.4704
Step [20], Loss: 0.4791
Step [30], Loss: 0.4464
Step [40], Loss: 0.4604
Step [50], Loss: 0.4402
Step [60], Loss: 0.4521
Step [70], Loss: 0.4549
Step [80], Loss: 0.4519
Step [90], Loss: 0.4803
Step [100], Loss: 0.4755
Step [110], Loss: 0.4596
Step [120], Loss: 0.4563
Step [130], Loss: 0.4513
Step [140], Loss: 0.4512
Step [150], Loss: 0.4752
Step [160], Loss: 0.4614
Step [170], Loss: 0.4890
Step [180], Loss: 0.4694
Step [190], Loss: 0.4612
Step [200], Loss: 0.4519
Step [210], Loss: 0.4500
Step [220], Loss: 0.4413
Step [230], Loss: 0.4564
Step [240], Loss: 0.4746
Step [250], Loss: 0.4674
Step [260], Loss: 0.4655
Step [270], Loss: 0.4632
Step [280], Loss: 0.4543
Step [290], Loss: 0.4777
Step [300], Loss: 0.4512
Step [310], Loss: 0.4743
Step [320], Loss: 0.4597
Step [330], Loss: 0.4607
Step [340], Loss: 0.4530
Step [350], Loss: 0.4608
Step [360], Loss: 0.4697
Step [370], Loss: 0.4799
Step [380], Loss: 0.4513
Step [390], Loss: 0.4707
Step [400], Loss: 0.4656
Step [410], Loss: 0.4829
Step [420], Loss: 0.4347
Step [430], Loss: 0.4513
Step [440], Loss: 0.4653
Step [450], Loss: 0.4599
Step [460], Loss: 0.4468
Step [470], Loss: 0.4385
Step [480], Loss: 0.4459
Step [490], Loss: 0.4432
correct predicitons: 84257.0
Total items 126797
Test Error: 
 Accuracy: 66.5%, Avg loss: 33.548940 

Epoch 11-----------------
Step [0], Loss: 0.4372
Step [10], Loss: 0.4527
Step [20], Loss: 0.4518
Step [30], Loss: 0.4585
Step [40], Loss: 0.4701
Step [50], Loss: 0.4487
Step [60], Loss: 0.4290
Step [70], Loss: 0.4543
Step [80], Loss: 0.4290
Step [90], Loss: 0.4464
Step [100], Loss: 0.4696
Step [110], Loss: 0.4413
Step [120], Loss: 0.4275
Step [130], Loss: 0.4698
Step [140], Loss: 0.4588
Step [150], Loss: 0.4716
Step [160], Loss: 0.4696
Step [170], Loss: 0.4452
Step [180], Loss: 0.4399
Step [190], Loss: 0.4464
Step [200], Loss: 0.4381
Step [210], Loss: 0.4500
Step [220], Loss: 0.4497
Step [230], Loss: 0.4429
Step [240], Loss: 0.4662
Step [250], Loss: 0.4488
Step [260], Loss: 0.4411
Step [270], Loss: 0.4637
Step [280], Loss: 0.4393
Step [290], Loss: 0.4399
Step [300], Loss: 0.4740
Step [310], Loss: 0.4397
Step [320], Loss: 0.4759
Step [330], Loss: 0.4552
Step [340], Loss: 0.4520
Step [350], Loss: 0.4502
Step [360], Loss: 0.4411
Step [370], Loss: 0.4524
Step [380], Loss: 0.4539
Step [390], Loss: 0.4257
Step [400], Loss: 0.4387
Step [410], Loss: 0.4637
Step [420], Loss: 0.4539
Step [430], Loss: 0.4469
Step [440], Loss: 0.4573
Step [450], Loss: 0.4537
Step [460], Loss: 0.4467
Step [470], Loss: 0.4651
Step [480], Loss: 0.4705
Step [490], Loss: 0.4597
correct predicitons: 84137.0
Total items 126797
Test Error: 
 Accuracy: 66.4%, Avg loss: 33.642779 

Early stopping triggered
Training Complete

Confusion Matrix:
            Predicted 0    Predicted 1
True 0      8841           1314
True 1      4805           4061
